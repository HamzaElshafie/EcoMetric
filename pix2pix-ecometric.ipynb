{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2008381,"sourceType":"datasetVersion","datasetId":1201791}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-20T10:04:10.921673Z","iopub.execute_input":"2024-06-20T10:04:10.922303Z","iopub.status.idle":"2024-06-20T10:04:10.928151Z","shell.execute_reply.started":"2024-06-20T10:04:10.922268Z","shell.execute_reply":"2024-06-20T10:04:10.927297Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport statistics\nfrom tqdm import tqdm\nimport pickle\nfrom PIL import Image\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n\n# Clear GPU cache\ntorch.cuda.empty_cache()\n\n# Define Gray transform\nclass Gray(object):\n    def __call__(self, img):\n        gray = img.convert('L')\n        return gray\n\n# Custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, root_s1, root_s2, transform_s1=None, transform_s2=None):\n        self.root_s1 = root_s1\n        self.root_s2 = root_s2\n        self.transform_s1 = transform_s1\n        self.transform_s2 = transform_s2\n        self.s1_images = sorted(os.listdir(root_s1))\n        self.s2_images = sorted(os.listdir(root_s2))\n        assert len(self.s1_images) == len(self.s2_images), \"Mismatched number of images in s1 and s2 directories\"\n\n    def __len__(self):\n        return len(self.s1_images)\n\n    def __getitem__(self, idx):\n        img_s1_path = os.path.join(self.root_s1, self.s1_images[idx])\n        img_s2_path = os.path.join(self.root_s2, self.s2_images[idx])\n        img_s1 = Image.open(img_s1_path).convert(\"RGB\")\n        img_s2 = Image.open(img_s2_path).convert(\"RGB\")\n\n        if self.transform_s1:\n            img_s1 = self.transform_s1(img_s1)\n        if self.transform_s2:\n            img_s2 = self.transform_s2(img_s2)\n\n        return img_s1, img_s2\n\n# Load datasets\ndef load_datasets():\n    SAR_transform = transforms.Compose([\n        Gray(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5,), std=(0.5,))\n    ])\n    \n    opt_transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n    ])\n    \n    dataset = CustomDataset(\n        root_s1='/kaggle/input/sentinel12-image-pairs-segregated-by-terrain/v_2/agri/s1',\n        root_s2='/kaggle/input/sentinel12-image-pairs-segregated-by-terrain/v_2/agri/s2',\n        transform_s1=SAR_transform,\n        transform_s2=opt_transform\n    )\n    \n    train_loader = DataLoader(\n        dataset,\n        batch_size=32,  # Increased batch size\n        shuffle=True,\n        num_workers=4,\n        pin_memory=True\n    )\n    return train_loader\n\n# Define Generator\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.enc1 = self.conv_bn_relu(1, 64, kernel_size=5)\n        self.enc2 = self.conv_bn_relu(64, 128, kernel_size=3, pool_kernel=4)\n        self.enc3 = self.conv_bn_relu(128, 256, kernel_size=3, pool_kernel=2)\n        self.enc4 = self.conv_bn_relu(256, 512, kernel_size=3, pool_kernel=2)\n\n        self.dec1 = self.conv_bn_relu(512, 256, kernel_size=3, pool_kernel=-2, flag=True, enc=False)\n        self.dec2 = self.conv_bn_relu(256+256, 128, kernel_size=3, pool_kernel=-2, flag=True, enc=False)\n        self.dec3 = self.conv_bn_relu(128+128, 64, kernel_size=3, pool_kernel=-4, enc=False)\n        self.dec4 = nn.Sequential(\n            nn.Conv2d(64 + 64, 3, kernel_size=5, padding=2),\n            nn.Tanh()\n        )\n  \n    def conv_bn_relu(self, in_ch, out_ch, kernel_size=3, pool_kernel=None, flag=None, enc=True):\n        layers = []\n        if pool_kernel is not None:\n            if pool_kernel > 0:\n                layers.append(nn.AvgPool2d(pool_kernel))\n            elif pool_kernel < 0:\n                layers.append(nn.UpsamplingNearest2d(scale_factor=-pool_kernel))\n        layers.append(nn.Conv2d(in_ch, out_ch, kernel_size, padding=(kernel_size - 1) // 2))\n        layers.append(nn.BatchNorm2d(out_ch))\n        if flag is not None:\n            layers.append(nn.Dropout2d(0.5))\n        if enc:\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n        else:\n            layers.append(nn.ReLU(inplace=True))\n        return nn.Sequential(*layers)\n  \n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(x1)\n        x3 = self.enc3(x2)\n        x4 = self.enc4(x3)\n        out = self.dec1(x4)\n        out = self.dec2(torch.cat([out, x3], dim=1))\n        out = self.dec3(torch.cat([out, x2], dim=1))\n        out = self.dec4(torch.cat([out, x1], dim=1))\n        return out\n\n# Define Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.conv1 = self.conv_bn_relu(4, 16, kernel_size=5, reps=1)\n        self.conv2 = self.conv_bn_relu(16, 32, pool_kernel=4)\n        self.conv3 = self.conv_bn_relu(32, 64, pool_kernel=2)\n        self.out_patch = nn.Conv2d(64, 1, kernel_size=1)\n\n    def conv_bn_relu(self, in_ch, out_ch, kernel_size=3, pool_kernel=None, reps=2):\n        layers = []\n        for i in range(reps):\n            if i == 0 and pool_kernel is not None:\n                layers.append(nn.AvgPool2d(pool_kernel))\n            layers.append(nn.Conv2d(in_ch if i == 0 else out_ch,\n                                  out_ch, kernel_size, padding=(kernel_size - 1) // 2))\n            layers.append(nn.BatchNorm2d(out_ch))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv3(self.conv2(self.conv1(x)))\n        return self.out_patch(out)\n\n# Training function\ndef train():\n    torch.backends.cudnn.benchmark = True\n\n    model_G, model_D = Generator(), Discriminator()\n    model_G, model_D = nn.DataParallel(model_G), nn.DataParallel(model_D)\n    model_G, model_D = model_G.to(device), model_D.to(device)\n\n    params_G = torch.optim.Adam(model_G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    params_D = torch.optim.Adam(model_D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n    ones = torch.ones(32, 1, 32, 32).to(device)  # Match batch size\n    zeros = torch.zeros(32, 1, 32, 32).to(device)  # Match batch size\n    bce_loss = nn.BCEWithLogitsLoss()\n    mae_loss = nn.L1Loss()\n\n    result = {\"log_loss_G_sum\": [], \"log_loss_G_bce\": [], \"log_loss_G_mae\": [], \"log_loss_D\": []}\n    \n    dataset = load_datasets()\n    \n    for epoch in range(100):\n        log_loss_G_sum, log_loss_G_bce, log_loss_G_mae, log_loss_D = [], [], [], []\n\n        with tqdm(total=len(dataset), desc=f\"Epoch {epoch + 1}/100\") as pbar:\n            for input_gray, real_color in dataset:\n                batch_len = len(real_color)\n                real_color, input_gray = real_color.to(device), input_gray.to(device)\n\n                fake_color = model_G(input_gray)\n                fake_color_tensor = fake_color.detach()\n                LAMBD = 100.0 \n                out = model_D(torch.cat([fake_color, input_gray], dim=1))\n                loss_G_bce = bce_loss(out, ones[:batch_len])\n                loss_G_mae = LAMBD * mae_loss(fake_color, real_color)\n                loss_G_sum = loss_G_bce + loss_G_mae\n                log_loss_G_bce.append(loss_G_bce.item())\n                log_loss_G_mae.append(loss_G_mae.item())\n                log_loss_G_sum.append(loss_G_sum.item())\n              \n                params_D.zero_grad()\n                params_G.zero_grad()\n                loss_G_sum.backward()\n                params_G.step()\n\n                ### Discriminator\n                real_out = model_D(torch.cat([real_color, input_gray], dim=1))\n                loss_D_real = bce_loss(real_out, ones[:batch_len])\n                \n                fake_out = model_D(torch.cat([fake_color_tensor, input_gray], dim=1))\n                loss_D_fake = bce_loss(fake_out, zeros[:batch_len])\n                \n                loss_D = loss_D_real + loss_D_fake\n                log_loss_D.append(loss_D.item())\n                \n                params_D.zero_grad()\n                params_G.zero_grad()\n                loss_D.backward()\n                params_D.step()\n                \n                pbar.update(1)\n                pbar.set_postfix({\n                    \"loss_G_sum\": statistics.mean(log_loss_G_sum),\n                    \"loss_G_bce\": statistics.mean(log_loss_G_bce),\n                    \"loss_G_mae\": statistics.mean(log_loss_G_mae),\n                    \"loss_D\": statistics.mean(log_loss_D)\n                })\n\n        result[\"log_loss_G_sum\"].append(statistics.mean(log_loss_G_sum))\n        result[\"log_loss_G_bce\"].append(statistics.mean(log_loss_G_bce))\n        result[\"log_loss_G_mae\"].append(statistics.mean(log_loss_G_mae))\n        result[\"log_loss_D\"].append(statistics.mean(log_loss_D))\n        \n        if not os.path.exists(\"SARtoOpt\"):\n            os.mkdir(\"SARtoOpt\")\n        \n        torchvision.utils.save_image(input_gray[:min(batch_len, 100)],\n                                f\"SARtoOpt/gray_epoch_{epoch:03}.png\",\n                                normalize=True)\n        torchvision.utils.save_image(fake_color_tensor[:min(batch_len, 100)],\n                                f\"SARtoOpt/fake_epoch_{epoch:03}.png\",\n                                normalize=True)\n        torchvision.utils.save_image(real_color[:min(batch_len, 100)],\n                                f\"SARtoOpt/real_epoch_{epoch:03}.png\",\n                                normalize=True)\n\n        if not os.path.exists(\"SARtoOpt/models\"):\n            os.mkdir(\"SARtoOpt/models\")\n        if epoch % 10 == 0 or epoch == 99:\n            torch.save(model_G.state_dict(), f\"SARtoOpt/models/gen_{epoch:03}.pt\")                        \n            torch.save(model_D.state_dict(), f\"SARtoOpt/models/dis_{epoch:03}.pt\")                        \n        \n    with open(\"SARtoOpt/logs.pkl\", \"wb\") as fp:\n        pickle.dump(result, fp)\n    \n    plt.plot(result[\"log_loss_G_sum\"], color=\"red\")\n    plt.plot(result[\"log_loss_G_bce\"], color=\"blue\")\n    plt.plot(result[\"log_loss_G_mae\"], color=\"green\")\n    plt.plot(result[\"log_loss_D\"], color=\"black\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    train()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T10:04:10.929883Z","iopub.execute_input":"2024-06-20T10:04:10.930621Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100:  93%|█████████▎| 116/125 [09:16<00:43,  4.81s/it, loss_G_sum=32, loss_G_bce=1.09, loss_G_mae=30.9, loss_D=0.871]  ","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}